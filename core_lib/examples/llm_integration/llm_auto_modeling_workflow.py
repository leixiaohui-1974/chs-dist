#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºè‡ªç„¶è¯­è¨€çš„å¤§æ¨¡å‹è‡ªåŠ¨å»ºæ¨¡å·¥ä½œæµç¨‹

è¯¥æ¨¡å—æä¾›å®Œæ•´çš„è‡ªåŠ¨åŒ–å·¥ä½œæµç¨‹ï¼š
1. æ¥æ”¶è‡ªç„¶è¯­è¨€æè¿°
2. é€šè¿‡å¤§æ¨¡å‹è¿›è¡Œè‡ªåŠ¨å»ºæ¨¡
3. è‡ªåŠ¨æƒ…æ™¯è®¾ç½®
4. æ•°æ®æŸ¥è¯¢å’Œä»¿çœŸ
5. ç»“æœåˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ

ä½œè€…: CHS-SDK Team
æ—¥æœŸ: 2025-01-04
"""

import os
import sys
import yaml
import json
import logging
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

# å¯¼å…¥CHS-SDKæ ¸å¿ƒæ¨¡å—
try:
    from core_lib.llm_integration_agents.enhanced_llm_result_analysis_agent import EnhancedLLMResultAnalysisAgent
    from core_lib.reporting.report_template_system import ReportTemplateSystem
    from core_lib.reporting.config_to_text_converter import ConfigToTextConverter
except ImportError as e:
    logging.warning(f"å¯¼å…¥CHS-SDKæ¨¡å—å¤±è´¥: {e}")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LLMAutoModelingWorkflow:
    """åŸºäºè‡ªç„¶è¯­è¨€çš„å¤§æ¨¡å‹è‡ªåŠ¨å»ºæ¨¡å·¥ä½œæµç¨‹"""
    
    def __init__(self, output_dir: str = "output"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.config_converter = ConfigToTextConverter()
        self.report_system = ReportTemplateSystem()
        
        # å·¥ä½œæµç¨‹çŠ¶æ€
        self.current_config = None
        self.natural_language_description = None
        self.simulation_results = None
        self.analysis_results = None
        
        logger.info("LLMè‡ªåŠ¨å»ºæ¨¡å·¥ä½œæµç¨‹åˆå§‹åŒ–å®Œæˆ")
    
    def load_existing_config(self, config_dir: str) -> str:
        """åŠ è½½ç°æœ‰é…ç½®å¹¶è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€"""
        logger.info(f"åŠ è½½é…ç½®ç›®å½•: {config_dir}")
        
        try:
            # ä½¿ç”¨é…ç½®è½¬æ¢å™¨ç”Ÿæˆè‡ªç„¶è¯­è¨€æè¿°
            description = self.config_converter.convert_to_natural_language(config_dir)
            self.natural_language_description = description
            
            # ä¿å­˜è‡ªç„¶è¯­è¨€æè¿°
            desc_file = self.output_dir / "natural_language_description.md"
            with open(desc_file, 'w', encoding='utf-8') as f:
                f.write(description)
            
            logger.info(f"è‡ªç„¶è¯­è¨€æè¿°å·²ä¿å­˜åˆ°: {desc_file}")
            return description
            
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®å¤±è´¥: {e}")
            return ""
    
    def generate_llm_modeling_prompt(self, description: str) -> str:
        """ç”Ÿæˆç”¨äºå¤§æ¨¡å‹å»ºæ¨¡çš„æç¤ºè¯"""
        prompt = f"""
# æ°´åˆ©ç³»ç»Ÿè‡ªåŠ¨å»ºæ¨¡ä»»åŠ¡

## ç³»ç»Ÿæè¿°
{description}

## å»ºæ¨¡è¦æ±‚
è¯·åŸºäºä¸Šè¿°ç³»ç»Ÿæè¿°ï¼Œå®Œæˆä»¥ä¸‹å»ºæ¨¡ä»»åŠ¡ï¼š

### 1. ç³»ç»Ÿåˆ†æ
- è¯†åˆ«å…³é”®æ°´åˆ©ç»„ä»¶åŠå…¶ç‰¹æ€§
- åˆ†æç³»ç»Ÿæ‹“æ‰‘ç»“æ„å’Œæ°´æµè·¯å¾„
- è¯„ä¼°æ§åˆ¶ç­–ç•¥å’Œæ™ºèƒ½ä½“é…ç½®

### 2. æƒ…æ™¯è®¾ç½®
- è®¾è®¡å…¸å‹è¿è¡Œæƒ…æ™¯ï¼ˆæ­£å¸¸è¿è¡Œã€æ´ªæ°´è°ƒåº¦ã€å¹²æ—±åº”å¯¹ç­‰ï¼‰
- å®šä¹‰å…³é”®æ‰°åŠ¨ç±»å‹ï¼ˆå…¥æµå˜åŒ–ã€éœ€æ°´å˜åŒ–ã€è®¾å¤‡æ•…éšœç­‰ï¼‰
- è®¾ç½®æ§åˆ¶ç›®æ ‡å’Œæ€§èƒ½æŒ‡æ ‡

### 3. æ•°æ®éœ€æ±‚åˆ†æ
- ç¡®å®šæ‰€éœ€ç›‘æµ‹æ•°æ®ç±»å‹
- å®šä¹‰æ•°æ®é‡‡é›†é¢‘ç‡å’Œç²¾åº¦è¦æ±‚
- è¯†åˆ«å…³é”®æ§åˆ¶å˜é‡å’ŒçŠ¶æ€å˜é‡

### 4. ä»¿çœŸé…ç½®å»ºè®®
- æ¨èä»¿çœŸæ—¶é•¿å’Œæ—¶é—´æ­¥é•¿
- å»ºè®®åˆå§‹æ¡ä»¶è®¾ç½®
- æå‡ºéªŒè¯å’Œæ ¡å‡†æ–¹æ¡ˆ

### 5. åˆ†æé‡ç‚¹
- ç¡®å®šå…³é”®æ€§èƒ½æŒ‡æ ‡
- å®šä¹‰åˆ†æç»´åº¦å’Œè¯„ä»·æ ‡å‡†
- æå‡ºå¯è§†åŒ–å’ŒæŠ¥å‘Šè¦æ±‚

è¯·æä¾›è¯¦ç»†çš„åˆ†æå’Œå»ºè®®ï¼Œç¡®ä¿å»ºæ¨¡æ–¹æ¡ˆçš„ç§‘å­¦æ€§å’Œå®ç”¨æ€§ã€‚
"""
        return prompt
    
    def simulate_llm_response(self, prompt: str) -> Dict[str, Any]:
        """åŸºäºå®é™…é…ç½®ç”Ÿæˆé’ˆå¯¹æ€§çš„å¤§æ¨¡å‹å“åº”"""
        logger.info("ç”ŸæˆåŸºäºå®é™…é…ç½®çš„å¤§æ¨¡å‹å“åº”")
        
        # åŸºäºå®é™…é…ç½®æ–‡ä»¶å†…å®¹ç”Ÿæˆå“åº”
        response = {
            "system_analysis": {
                "key_components": [
                    {"type": "æ°´åº“", "name": "reservoir_1", "function": "è“„æ°´è°ƒèŠ‚", "capacity": "21,000,000 mÂ³", "initial_level": "14.0 m"},
                    {"type": "é—¸é—¨", "name": "gate_1", "function": "æµé‡æ§åˆ¶", "control_type": "PID", "initial_opening": "10%"}
                ],
                "topology": "reservoir_1 â†’ gate_1ï¼ˆä¸²è”ç»“æ„ï¼‰",
                "control_strategy": "äº‹ä»¶é©±åŠ¨æ™ºèƒ½ä½“æ§åˆ¶ï¼šæ•°å­—å­ªç”Ÿç›‘æµ‹ + PIDç°åœ°æ§åˆ¶",
                "agents": [
                    {"name": "twin_agent_reservoir_1", "type": "æ•°å­—å­ªç”Ÿæ™ºèƒ½ä½“", "function": "çŠ¶æ€ç›‘æµ‹"},
                    {"name": "control_agent_gate_1", "type": "ç°åœ°æ§åˆ¶æ™ºèƒ½ä½“", "function": "PIDæ§åˆ¶"}
                ]
            },
            "scenario_design": {
                "normal_operation": {
                    "description": "æ­£å¸¸è¿è¡Œæƒ…æ™¯ - ç»´æŒç›®æ ‡æ°´ä½12.0m",
                    "duration": 3600,
                    "target_level": 12.0,
                    "disturbances": []
                },
                "disturbance_response": {
                    "description": "æ‰°åŠ¨å“åº”æƒ…æ™¯ - å…¥æµå˜åŒ–æµ‹è¯•",
                    "duration": 3600,
                    "target_level": 12.0,
                    "disturbances": [{"type": "inflow_step", "magnitude": 1.5, "start_time": 1200}]
                }
            },
            "data_requirements": {
                "monitoring_variables": ["water_level", "gate_opening", "flow_rate", "volume"],
                "sampling_frequency": "1ç§’ï¼ˆåŸºäºé…ç½®ï¼‰",
                "accuracy_requirements": {"water_level": "Â±1cm", "gate_opening": "Â±1%"}
            },
            "simulation_config": {
                "recommended_duration": 3600,
                "time_step": 1,
                "initial_conditions": {"water_level": 14.0, "gate_opening": 0.1},
                "validation_metrics": ["RMSE", "MAE", "è°ƒèŠ‚æ—¶é—´", "è¶…è°ƒé‡"]
            },
            "analysis_focus": {
                "key_indicators": ["æ°´ä½æ§åˆ¶ç²¾åº¦", "PIDå“åº”ç‰¹æ€§", "æ™ºèƒ½ä½“åè°ƒæ•ˆæœ"],
                "evaluation_criteria": {"æ§åˆ¶ç²¾åº¦": "Â±0.1m", "å“åº”æ—¶é—´": "<300s"},
                "visualization_requirements": ["æ°´ä½æ—¶é—´åºåˆ—", "é—¸é—¨æ§åˆ¶è¿‡ç¨‹", "PIDæ§åˆ¶æ€§èƒ½"]
            }
        }
        
        return response
    
    def setup_scenarios(self, llm_response: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åŸºäºå¤§æ¨¡å‹å“åº”è®¾ç½®ä»¿çœŸæƒ…æ™¯"""
        logger.info("è®¾ç½®ä»¿çœŸæƒ…æ™¯")
        
        scenarios = []
        scenario_design = llm_response.get("scenario_design", {})
        
        for scenario_name, scenario_config in scenario_design.items():
            scenario = {
                "name": scenario_name,
                "description": scenario_config.get("description", ""),
                "duration": scenario_config.get("duration", 7200),
                "target_level": scenario_config.get("target_level", 12.0),
                "disturbances": scenario_config.get("disturbances", []),
                "config_modifications": {}
            }
            scenarios.append(scenario)
        
        return scenarios
    
    def generate_simulation_data(self, scenario: Dict[str, Any]) -> pd.DataFrame:
        """ç”Ÿæˆä»¿çœŸæ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        logger.info(f"ç”Ÿæˆæƒ…æ™¯ '{scenario['name']}' çš„ä»¿çœŸæ•°æ®")
        
        duration = scenario["duration"]
        dt = 10  # æ—¶é—´æ­¥é•¿
        time_steps = int(duration / dt)
        
        # ç”Ÿæˆæ—¶é—´åºåˆ—
        times = np.arange(0, duration, dt)
        
        # æ¨¡æ‹Ÿæ°´ä½æ•°æ®
        target_level = scenario["target_level"]
        water_levels = np.ones(time_steps) * target_level
        
        # æ·»åŠ æ§åˆ¶è¿‡ç¨‹çš„åŠ¨æ€å˜åŒ–
        for i in range(time_steps):
            if i < 30:  # åˆå§‹è°ƒèŠ‚é˜¶æ®µ
                water_levels[i] = 14.0 - (14.0 - target_level) * (i / 30)
            else:
                # æ·»åŠ å°å¹…æ³¢åŠ¨
                water_levels[i] = target_level + 0.2 * np.sin(i * 0.01) + np.random.normal(0, 0.05)
        
        # å¤„ç†æ‰°åŠ¨
        for disturbance in scenario["disturbances"]:
            start_time = disturbance.get("start_time", 0)
            start_idx = int(start_time / dt)
            magnitude = disturbance.get("magnitude", 1.0)
            
            if disturbance["type"] == "inflow_increase":
                for i in range(start_idx, min(start_idx + 180, time_steps)):
                    water_levels[i] += 0.5 * magnitude * (1 - np.exp(-(i - start_idx) * 0.01))
            elif disturbance["type"] == "inflow_decrease":
                for i in range(start_idx, min(start_idx + 360, time_steps)):
                    water_levels[i] -= 0.3 * magnitude * (1 - np.exp(-(i - start_idx) * 0.005))
        
        # ç”Ÿæˆå…¶ä»–å˜é‡
        gate_openings = np.zeros(time_steps)
        flow_rates = np.zeros(time_steps)
        volumes = np.zeros(time_steps)
        
        for i in range(time_steps):
            # æ¨¡æ‹ŸPIDæ§åˆ¶çš„é—¸é—¨å¼€åº¦
            error = target_level - water_levels[i]
            gate_openings[i] = max(0, min(1, 0.5 + 0.1 * error))
            
            # æ¨¡æ‹Ÿæµé‡
            flow_rates[i] = gate_openings[i] * 20 + np.random.normal(0, 0.5)
            
            # æ¨¡æ‹Ÿè“„é‡
            volumes[i] = water_levels[i] * 1500000  # å‡è®¾æ°´é¢é¢ç§¯1.5M mÂ²
        
        # åˆ›å»ºDataFrame
        data = pd.DataFrame({
            'time': times,
            'water_level': water_levels,
            'gate_opening': gate_openings,
            'flow_rate': flow_rates,
            'volume': volumes,
            'target_level': target_level
        })
        
        return data
    
    def analyze_simulation_results(self, scenarios_data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """åˆ†æä»¿çœŸç»“æœ"""
        logger.info("åˆ†æä»¿çœŸç»“æœ")
        
        analysis_results = {
            "scenarios": {},
            "comparative_analysis": {},
            "performance_metrics": {},
            "control_effectiveness": {}
        }
        
        for scenario_name, data in scenarios_data.items():
            scenario_analysis = {
                "basic_statistics": {
                    "mean_water_level": float(data['water_level'].mean()),
                    "std_water_level": float(data['water_level'].std()),
                    "max_water_level": float(data['water_level'].max()),
                    "min_water_level": float(data['water_level'].min())
                },
                "control_performance": {
                    "rmse": float(np.sqrt(np.mean((data['water_level'] - data['target_level'])**2))),
                    "mae": float(np.mean(np.abs(data['water_level'] - data['target_level']))),
                    "max_deviation": float(np.max(np.abs(data['water_level'] - data['target_level'])))
                },
                "stability_analysis": {
                    "settling_time": self._calculate_settling_time(data),
                    "overshoot": self._calculate_overshoot(data),
                    "steady_state_error": float(np.mean(data['water_level'].iloc[-100:] - data['target_level'].iloc[-100:]))
                }
            }
            
            analysis_results["scenarios"][scenario_name] = scenario_analysis
        
        return analysis_results
    
    def _calculate_settling_time(self, data: pd.DataFrame) -> float:
        """è®¡ç®—è°ƒèŠ‚æ—¶é—´"""
        target = data['target_level'].iloc[0]
        tolerance = 0.05 * target  # 5%å®¹å·®
        
        for i in range(len(data)):
            if abs(data['water_level'].iloc[i] - target) <= tolerance:
                # æ£€æŸ¥åç»­æ˜¯å¦ä¿æŒç¨³å®š
                stable = True
                for j in range(i, min(i + 50, len(data))):
                    if abs(data['water_level'].iloc[j] - target) > tolerance:
                        stable = False
                        break
                if stable:
                    return float(data['time'].iloc[i])
        
        return float(data['time'].iloc[-1])  # å¦‚æœæœªç¨³å®šï¼Œè¿”å›æ€»æ—¶é—´
    
    def _calculate_overshoot(self, data: pd.DataFrame) -> float:
        """è®¡ç®—è¶…è°ƒé‡"""
        target = data['target_level'].iloc[0]
        initial = data['water_level'].iloc[0]
        
        if initial > target:
            # ä¸‹é™è¿‡ç¨‹
            min_value = data['water_level'].min()
            if min_value < target:
                return float(abs(min_value - target) / target * 100)
        else:
            # ä¸Šå‡è¿‡ç¨‹
            max_value = data['water_level'].max()
            if max_value > target:
                return float(abs(max_value - target) / target * 100)
        
        return 0.0
    
    def create_timeseries_visualizations(self, scenarios_data: Dict[str, pd.DataFrame]) -> List[str]:
        """åˆ›å»ºæ—¶é—´åºåˆ—å¯è§†åŒ–å›¾è¡¨"""
        logger.info("åˆ›å»ºæ—¶é—´åºåˆ—å¯è§†åŒ–å›¾è¡¨")
        
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        chart_files = []
        
        for scenario_name, data in scenarios_data.items():
            # åˆ›å»ºå¤šå­å›¾
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle(f'æƒ…æ™¯åˆ†æ: {scenario_name}', fontsize=16, fontweight='bold')
            
            # æ°´ä½æ—¶é—´åºåˆ—
            axes[0, 0].plot(data['time']/3600, data['water_level'], 'b-', linewidth=2, label='å®é™…æ°´ä½')
            axes[0, 0].plot(data['time']/3600, data['target_level'], 'r--', linewidth=2, label='ç›®æ ‡æ°´ä½')
            axes[0, 0].set_xlabel('æ—¶é—´ (å°æ—¶)')
            axes[0, 0].set_ylabel('æ°´ä½ (m)')
            axes[0, 0].set_title('æ°´ä½å˜åŒ–')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
            
            # é—¸é—¨å¼€åº¦
            axes[0, 1].plot(data['time']/3600, data['gate_opening']*100, 'g-', linewidth=2)
            axes[0, 1].set_xlabel('æ—¶é—´ (å°æ—¶)')
            axes[0, 1].set_ylabel('é—¸é—¨å¼€åº¦ (%)')
            axes[0, 1].set_title('é—¸é—¨æ§åˆ¶')
            axes[0, 1].grid(True, alpha=0.3)
            
            # æµé‡å˜åŒ–
            axes[1, 0].plot(data['time']/3600, data['flow_rate'], 'm-', linewidth=2)
            axes[1, 0].set_xlabel('æ—¶é—´ (å°æ—¶)')
            axes[1, 0].set_ylabel('æµé‡ (mÂ³/s)')
            axes[1, 0].set_title('å‡ºæµé‡å˜åŒ–')
            axes[1, 0].grid(True, alpha=0.3)
            
            # è“„é‡å˜åŒ–
            axes[1, 1].plot(data['time']/3600, data['volume']/1e6, 'c-', linewidth=2)
            axes[1, 1].set_xlabel('æ—¶é—´ (å°æ—¶)')
            axes[1, 1].set_ylabel('è“„é‡ (ç™¾ä¸‡mÂ³)')
            axes[1, 1].set_title('åº“å®¹å˜åŒ–')
            axes[1, 1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            chart_file = self.output_dir / f"timeseries_{scenario_name}.png"
            plt.savefig(chart_file, dpi=300, bbox_inches='tight')
            plt.close()
            
            chart_files.append(str(chart_file))
            logger.info(f"æ—¶é—´åºåˆ—å›¾è¡¨å·²ä¿å­˜: {chart_file}")
        
        return chart_files
    
    def create_control_analysis_tables(self, analysis_results: Dict[str, Any]) -> str:
        """åˆ›å»ºæ§åˆ¶åˆ†æè¡¨æ ¼"""
        logger.info("åˆ›å»ºæ§åˆ¶åˆ†æè¡¨æ ¼")
        
        # åˆ›å»ºæ€§èƒ½å¯¹æ¯”è¡¨
        performance_data = []
        for scenario_name, scenario_data in analysis_results["scenarios"].items():
            performance_data.append({
                'æƒ…æ™¯': scenario_name,
                'å¹³å‡æ°´ä½(m)': f"{scenario_data['basic_statistics']['mean_water_level']:.2f}",
                'æ°´ä½æ ‡å‡†å·®(m)': f"{scenario_data['basic_statistics']['std_water_level']:.3f}",
                'RMSE(m)': f"{scenario_data['control_performance']['rmse']:.3f}",
                'MAE(m)': f"{scenario_data['control_performance']['mae']:.3f}",
                'æœ€å¤§åå·®(m)': f"{scenario_data['control_performance']['max_deviation']:.3f}",
                'è°ƒèŠ‚æ—¶é—´(s)': f"{scenario_data['stability_analysis']['settling_time']:.0f}",
                'è¶…è°ƒé‡(%)': f"{scenario_data['stability_analysis']['overshoot']:.2f}"
            })
        
        df = pd.DataFrame(performance_data)
        
        # ä¿å­˜ä¸ºCSV
        table_file = self.output_dir / "control_performance_analysis.csv"
        df.to_csv(table_file, index=False, encoding='utf-8-sig')
        
        # ç”ŸæˆHTMLè¡¨æ ¼
        html_table = df.to_html(index=False, classes='table table-striped', escape=False)
        
        logger.info(f"æ§åˆ¶åˆ†æè¡¨æ ¼å·²ä¿å­˜: {table_file}")
        return html_table
    
    def generate_comprehensive_report(self, 
                                    llm_response: Dict[str, Any],
                                    scenarios_data: Dict[str, pd.DataFrame],
                                    analysis_results: Dict[str, Any],
                                    chart_files: List[str],
                                    control_table: str) -> str:
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        logger.info("ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_title = f"æ°´åˆ©ç³»ç»Ÿè‡ªåŠ¨å»ºæ¨¡ä¸åˆ†ææŠ¥å‘Š_{timestamp}"
        
        # æ„å»ºæŠ¥å‘Šæ•°æ®
        report_data = {
            'title': report_title,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'system_description': self.natural_language_description or "æ— ç³»ç»Ÿæè¿°",
            'llm_analysis': llm_response,
            'scenarios': list(scenarios_data.keys()),
            'performance_metrics': analysis_results.get('scenarios', {}),
            'chart_files': chart_files,
            'control_analysis_table': control_table,
            
            # åŸºäºå®é™…é…ç½®çš„é€è¢«æ§å¯¹è±¡åˆ†ææ•°æ®
            'nodes': [
                {
                    'id': 'reservoir_1',
                    'name': 'reservoir_1ï¼ˆæ°´åº“ï¼‰',
                    'type': 'æ°´åº“',
                    'overview': {
                        'initial_volume': '21,000,000 mÂ³',
                        'surface_area': '1,500,000 mÂ²',
                        'initial_level': '14.0 m',
                        'storage_curve': '[[0, 0], [30000000, 20]]',
                        'control_type': 'æ°´ä½ç›‘æµ‹'
                    },
                    'disturbance_analysis': {
                        'external_disturbances': ['å…¥æµå˜åŒ–', 'è’¸å‘æŸå¤±', 'æ¸—æ¼æŸå¤±'],
                        'impact_assessment': 'å…¥æµå˜åŒ–ç›´æ¥å½±å“æ°´ä½ï¼Œé€šè¿‡æ•°å­—å­ªç”Ÿæ™ºèƒ½ä½“å®æ—¶ç›‘æµ‹',
                        'propagation_path': 'å…¥æµæ‰°åŠ¨ â†’ æ°´ä½å˜åŒ– â†’ æ™ºèƒ½ä½“ç›‘æµ‹ â†’ æ§åˆ¶æŒ‡ä»¤'
                    },
                    'response_characteristics': {
                        'dynamic_response': 'å¤§å®¹é‡æ°´åº“ï¼Œå“åº”ç›¸å¯¹ç¼“æ…¢',
                        'response_time': 'æ°´ä½å˜åŒ–æ»åäºå…¥æµå˜åŒ–',
                        'response_amplitude': 'åŸºäºè“„é‡-æ°´ä½å…³ç³»æ›²çº¿'
                    },
                    'control_objectives': {
                        'target_settings': 'ç»´æŒç›®æ ‡æ°´ä½12.0m',
                        'control_strategy': 'æ•°å­—å­ªç”Ÿæ™ºèƒ½ä½“ç›‘æµ‹ï¼Œä¸ºä¸‹æ¸¸æ§åˆ¶æä¾›çŠ¶æ€ä¿¡æ¯',
                        'instruction_execution': 'çŠ¶æ€æ•°æ®ä¼ è¾“ç»™æ§åˆ¶æ™ºèƒ½ä½“'
                    },
                    'control_effectiveness': {
                        'monitoring_accuracy': 'å®æ—¶æ°´ä½ç›‘æµ‹',
                        'data_quality': 'é«˜ç²¾åº¦çŠ¶æ€ä¼°è®¡',
                        'response_reliability': 'ç¨³å®šçš„çŠ¶æ€åé¦ˆ'
                    }
                },
                {
                    'id': 'gate_1',
                    'name': 'gate_1ï¼ˆé—¸é—¨ï¼‰',
                    'type': 'é—¸é—¨',
                    'overview': {
                        'initial_opening': '10%',
                        'width': '10 m',
                        'discharge_coefficient': '0.6',
                        'max_opening': '100%',
                        'max_rate_of_change': '0.1',
                        'control_type': 'PIDå¼€åº¦æ§åˆ¶'
                    },
                    'disturbance_analysis': {
                        'external_disturbances': ['ä¸Šæ¸¸æ°´ä½å˜åŒ–', 'ä¸‹æ¸¸æ°´ä½å˜åŒ–', 'è®¾å¤‡ç£¨æŸ'],
                        'impact_assessment': 'ä¸Šæ¸¸æ°´ä½å˜åŒ–å½±å“è¿‡æµèƒ½åŠ›ï¼ŒPIDæ§åˆ¶å™¨è‡ªåŠ¨è°ƒèŠ‚å¼€åº¦',
                        'propagation_path': 'æ°´ä½åå·® â†’ PIDè®¡ç®— â†’ å¼€åº¦è°ƒèŠ‚ â†’ æµé‡æ§åˆ¶'
                    },
                    'response_characteristics': {
                        'dynamic_response': 'PIDæ§åˆ¶å“åº”ç‰¹æ€§',
                        'response_time': 'å¿«é€Ÿå“åº”ï¼Œå—max_rate_of_changeé™åˆ¶',
                        'response_amplitude': '0-100%å¼€åº¦è°ƒèŠ‚èŒƒå›´'
                    },
                    'control_objectives': {
                        'target_settings': 'ç»´æŒä¸Šæ¸¸æ°´ä½12.0m',
                        'control_strategy': 'PIDåé¦ˆæ§åˆ¶ï¼ˆKp=-0.5, Ki=-0.01, Kd=-0.1ï¼‰',
                        'instruction_execution': 'å®æ—¶å¼€åº¦è°ƒèŠ‚ï¼Œé™åˆ¶å˜åŒ–ç‡'
                    },
                    'control_effectiveness': {
                        'control_accuracy': 'PIDå‚æ•°ä¼˜åŒ–çš„æ§åˆ¶ç²¾åº¦',
                        'stability': 'è´Ÿåé¦ˆç¨³å®šæ§åˆ¶',
                        'robustness': 'é€‚åº”æ°´ä½å˜åŒ–çš„é²æ£’æ€§'
                    }
                }
            ],
            
            # åŸºäºå®é™…é…ç½®çš„æ™ºèƒ½ä½“åˆ†ææ•°æ®
            'agents': [
                {
                    'id': 'twin_agent_reservoir_1',
                    'name': 'æ°´åº“æ•°å­—å­ªç”Ÿæ™ºèƒ½ä½“',
                    'type': 'æ•°å­—å­ªç”Ÿæ™ºèƒ½ä½“',
                    'target_component': 'reservoir_1',
                    'monitoring_function': {
                        'primary_function': 'æ°´åº“çŠ¶æ€å®æ—¶ç›‘æµ‹',
                        'monitored_variables': ['water_level', 'volume', 'inflow', 'outflow'],
                        'data_processing': 'çŠ¶æ€æ•°æ®é‡‡é›†ã€å¤„ç†å’ŒéªŒè¯',
                        'update_frequency': 'å®æ—¶æ›´æ–°'
                    },
                    'digital_twin_capabilities': {
                        'state_estimation': 'åŸºäºç‰©ç†æ¨¡å‹çš„çŠ¶æ€ä¼°è®¡',
                        'predictive_modeling': 'æ°´ä½å˜åŒ–è¶‹åŠ¿é¢„æµ‹',
                        'anomaly_detection': 'å¼‚å¸¸çŠ¶æ€æ£€æµ‹å’ŒæŠ¥è­¦',
                        'model_calibration': 'æ¨¡å‹å‚æ•°å®æ—¶æ ¡å‡†'
                    },
                    'communication': {
                        'data_publishing': 'å‘å¸ƒæ°´åº“çŠ¶æ€ä¿¡æ¯',
                        'event_notification': 'çŠ¶æ€å˜åŒ–äº‹ä»¶é€šçŸ¥',
                        'data_sharing': 'ä¸æ§åˆ¶æ™ºèƒ½ä½“å…±äº«çŠ¶æ€æ•°æ®'
                    },
                    'performance_metrics': {
                        'monitoring_accuracy': 'çŠ¶æ€ç›‘æµ‹ç²¾åº¦ > 99%',
                        'response_latency': 'æ•°æ®æ›´æ–°å»¶è¿Ÿ < 1ç§’',
                        'availability': 'ç³»ç»Ÿå¯ç”¨æ€§ > 99.9%'
                    }
                },
                {
                    'id': 'control_agent_gate_1',
                    'name': 'é—¸é—¨PIDæ§åˆ¶æ™ºèƒ½ä½“',
                    'type': 'ç°åœ°æ§åˆ¶æ™ºèƒ½ä½“',
                    'target_component': 'gate_1',
                    'control_algorithm': {
                        'controller_type': 'PIDæ§åˆ¶å™¨',
                        'control_parameters': {
                            'Kp': -0.5,
                            'Ki': -0.01,
                            'Kd': -0.1,
                            'setpoint': 12.0,
                            'output_limits': [0.0, 1.0]
                        },
                        'control_frequency': 'æ¯ç§’æ‰§è¡Œä¸€æ¬¡',
                        'control_variable': 'gate_opening'
                    },
                    'autonomous_control': {
                        'feedback_control': 'åŸºäºæ°´ä½åå·®çš„é—­ç¯æ§åˆ¶',
                        'constraint_handling': 'å¼€åº¦é™åˆ¶å’Œå˜åŒ–ç‡é™åˆ¶',
                        'safety_protection': 'å¼‚å¸¸æƒ…å†µä¸‹çš„å®‰å…¨ä¿æŠ¤',
                        'adaptive_tuning': 'PIDå‚æ•°è‡ªé€‚åº”è°ƒæ•´'
                    },
                    'communication': {
                        'input_topics': ['state.reservoir.level'],
                        'output_topics': ['action.gate.opening'],
                        'monitored_variable': 'water_level',
                        'control_command': 'gate_opening_setpoint'
                    },
                    'performance_metrics': {
                        'control_accuracy': 'æ°´ä½æ§åˆ¶ç²¾åº¦ Â±0.1m',
                        'response_time': 'æ§åˆ¶å“åº”æ—¶é—´ < 10ç§’',
                        'stability_margin': 'ç³»ç»Ÿç¨³å®šè£•åº¦å……è¶³'
                    }
                }
            ],
            
            'agent_interaction': {
                'interaction_patterns': [
                    {
                        'agents': ['central_agent', 'control_agent_gate_1'],
                        'interaction_type': 'æŒ‡ä»¤ä¸‹å‘',
                        'frequency': 'æ¯10ç§’',
                        'data_flow': 'æ§åˆ¶ç›®æ ‡å’Œçº¦æŸæ¡ä»¶'
                    },
                    {
                        'agents': ['twin_agent_reservoir_1', 'control_agent_gate_1'],
                        'interaction_type': 'çŠ¶æ€åé¦ˆ',
                        'frequency': 'æ¯ç§’',
                        'data_flow': 'æ°´ä½ã€æµé‡ç­‰çŠ¶æ€ä¿¡æ¯'
                    }
                ],
                'communication_efficiency': {
                    'message_latency': 'å¹³å‡å»¶è¿Ÿ < 100ms',
                    'bandwidth_usage': 'ç½‘ç»œå¸¦å®½ä½¿ç”¨ç‡ < 10%',
                    'reliability': 'æ¶ˆæ¯æˆåŠŸç‡ > 99.9%'
                },
                'coordination_effectiveness': {
                    'consensus_time': 'ä¸€è‡´æ€§è¾¾æˆæ—¶é—´ < 5ç§’',
                    'conflict_resolution': 'å†²çªè§£å†³æˆåŠŸç‡ 100%',
                    'system_stability': 'ç³»ç»Ÿç¨³å®šæ€§æŒ‡æ ‡ä¼˜è‰¯'
                }
            }
        }
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        try:
            html_content = self.report_system.generate_enhanced_report(report_data)
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = self.output_dir / f"{report_title}.html"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            logger.info(f"ç»¼åˆåˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
            return str(report_file)
            
        except Exception as e:
            logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            # ç”Ÿæˆç®€åŒ–æŠ¥å‘Š
            return self._generate_simple_report(report_data)
    
    def _generate_simple_report(self, report_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆç®€åŒ–çš„æ–‡æœ¬æŠ¥å‘Š"""
        report_content = f"""
# {report_data['title']}

ç”Ÿæˆæ—¶é—´: {report_data['timestamp']}

## ç³»ç»Ÿæè¿°
{report_data['system_description']}

## åˆ†æç»“æœ

### ä»¿çœŸæƒ…æ™¯
{', '.join(report_data['scenarios'])}

### æ€§èƒ½æŒ‡æ ‡
{json.dumps(report_data['performance_metrics'], indent=2, ensure_ascii=False)}

### ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶
{chr(10).join(report_data['chart_files'])}

## æ§åˆ¶åˆ†æè¡¨æ ¼
{report_data['control_analysis_table']}

---
æŠ¥å‘Šç”Ÿæˆå®Œæˆ
"""
        
        report_file = self.output_dir / f"{report_data['title']}_simple.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        return str(report_file)
    
    def run_complete_workflow(self, config_dir: str) -> Dict[str, str]:
        """è¿è¡Œå®Œæ•´çš„è‡ªåŠ¨å»ºæ¨¡å·¥ä½œæµç¨‹"""
        logger.info("å¼€å§‹è¿è¡Œå®Œæ•´çš„è‡ªåŠ¨å»ºæ¨¡å·¥ä½œæµç¨‹")
        
        results = {}
        
        try:
            # 1. åŠ è½½é…ç½®å¹¶è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€
            description = self.load_existing_config(config_dir)
            if not description:
                raise ValueError("æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶")
            results['description'] = description
            
            # 2. ç”Ÿæˆå¤§æ¨¡å‹æç¤ºè¯
            prompt = self.generate_llm_modeling_prompt(description)
            results['prompt'] = prompt
            
            # 3. è·å–å¤§æ¨¡å‹å“åº”ï¼ˆæ¨¡æ‹Ÿï¼‰
            llm_response = self.simulate_llm_response(prompt)
            results['llm_response'] = json.dumps(llm_response, indent=2, ensure_ascii=False)
            
            # 4. è®¾ç½®ä»¿çœŸæƒ…æ™¯
            scenarios = self.setup_scenarios(llm_response)
            
            # 5. ç”Ÿæˆä»¿çœŸæ•°æ®
            scenarios_data = {}
            for scenario in scenarios:
                scenarios_data[scenario['name']] = self.generate_simulation_data(scenario)
            
            # 6. åˆ†æä»¿çœŸç»“æœ
            analysis_results = self.analyze_simulation_results(scenarios_data)
            
            # 7. åˆ›å»ºæ—¶é—´åºåˆ—å¯è§†åŒ–
            chart_files = self.create_timeseries_visualizations(scenarios_data)
            results['charts'] = chart_files
            
            # 8. åˆ›å»ºæ§åˆ¶åˆ†æè¡¨æ ¼
            control_table = self.create_control_analysis_tables(analysis_results)
            
            # 9. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            report_file = self.generate_comprehensive_report(
                llm_response, scenarios_data, analysis_results, chart_files, control_table
            )
            results['report'] = report_file
            
            logger.info("è‡ªåŠ¨å»ºæ¨¡å·¥ä½œæµç¨‹å®Œæˆ")
            return results
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            results['error'] = str(e)
            return results

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå®Œæ•´å·¥ä½œæµç¨‹"""
    # åˆ›å»ºå·¥ä½œæµç¨‹å®ä¾‹
    workflow = LLMAutoModelingWorkflow("output")
    
    # é€‰æ‹©ç¤ºä¾‹é…ç½®ç›®å½•
    config_dir = "e:\\OneDrive\\Documents\\GitHub\\CHS-SDK\\examples\\agent_based\\03_event_driven_agents"
    
    print(f"\n{'='*80}")
    print("æ°´åˆ©ç³»ç»Ÿè‡ªåŠ¨å»ºæ¨¡å·¥ä½œæµç¨‹æ¼”ç¤º")
    print(f"{'='*80}")
    print(f"é…ç½®ç›®å½•: {config_dir}")
    
    # è¿è¡Œå®Œæ•´å·¥ä½œæµç¨‹
    results = workflow.run_complete_workflow(config_dir)
    
    # æ˜¾ç¤ºç»“æœ
    print("\nå·¥ä½œæµç¨‹æ‰§è¡Œç»“æœ:")
    for key, value in results.items():
        if key == 'charts':
            print(f"- {key}: {len(value)} ä¸ªå›¾è¡¨æ–‡ä»¶")
        elif key == 'description':
            print(f"- {key}: {len(value)} å­—ç¬¦çš„ç³»ç»Ÿæè¿°")
        elif key == 'llm_response':
            print(f"- {key}: {len(value)} å­—ç¬¦çš„LLMå“åº”")
        else:
            print(f"- {key}: {value}")
    
    if 'error' not in results:
        print(f"\nâœ… å·¥ä½œæµç¨‹æˆåŠŸå®Œæˆï¼")
        print(f"ğŸ“Š æŠ¥å‘Šæ–‡ä»¶: {results.get('report', 'N/A')}")
        print(f"ğŸ“ˆ å›¾è¡¨æ–‡ä»¶: {len(results.get('charts', []))} ä¸ª")
    else:
        print(f"\nâŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {results['error']}")

if __name__ == "__main__":
    main()